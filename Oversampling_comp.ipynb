{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Oversampling_comp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riju-jec/Oversampling/blob/main/Oversampling_comp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCiU5PokXjd6"
      },
      "source": [
        "Aim - to explore different oversampling techniques and exploring which algorithm can work on what type of datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMnMd8FM4oXM"
      },
      "source": [
        "# !rm -r /content/Oversampling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB-IhL6p-ELz",
        "outputId": "a33fdbb5-cf9c-49f2-971d-074f2702712e"
      },
      "source": [
        "!git clone https://github.com/riju-jec/Oversampling.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Oversampling'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/42)\u001b[K\rremote: Counting objects:   4% (2/42)\u001b[K\rremote: Counting objects:   7% (3/42)\u001b[K\rremote: Counting objects:   9% (4/42)\u001b[K\rremote: Counting objects:  11% (5/42)\u001b[K\rremote: Counting objects:  14% (6/42)\u001b[K\rremote: Counting objects:  16% (7/42)\u001b[K\rremote: Counting objects:  19% (8/42)\u001b[K\rremote: Counting objects:  21% (9/42)\u001b[K\rremote: Counting objects:  23% (10/42)\u001b[K\rremote: Counting objects:  26% (11/42)\u001b[K\rremote: Counting objects:  28% (12/42)\u001b[K\rremote: Counting objects:  30% (13/42)\u001b[K\rremote: Counting objects:  33% (14/42)\u001b[K\rremote: Counting objects:  35% (15/42)\u001b[K\rremote: Counting objects:  38% (16/42)\u001b[K\rremote: Counting objects:  40% (17/42)\u001b[K\rremote: Counting objects:  42% (18/42)\u001b[K\rremote: Counting objects:  45% (19/42)\u001b[K\rremote: Counting objects:  47% (20/42)\u001b[K\rremote: Counting objects:  50% (21/42)\u001b[K\rremote: Counting objects:  52% (22/42)\u001b[K\rremote: Counting objects:  54% (23/42)\u001b[K\rremote: Counting objects:  57% (24/42)\u001b[K\rremote: Counting objects:  59% (25/42)\u001b[K\rremote: Counting objects:  61% (26/42)\u001b[K\rremote: Counting objects:  64% (27/42)\u001b[K\rremote: Counting objects:  66% (28/42)\u001b[K\rremote: Counting objects:  69% (29/42)\u001b[K\rremote: Counting objects:  71% (30/42)\u001b[K\rremote: Counting objects:  73% (31/42)\u001b[K\rremote: Counting objects:  76% (32/42)\u001b[K\rremote: Counting objects:  78% (33/42)\u001b[K\rremote: Counting objects:  80% (34/42)\u001b[K\rremote: Counting objects:  83% (35/42)\u001b[K\rremote: Counting objects:  85% (36/42)\u001b[K\rremote: Counting objects:  88% (37/42)\u001b[K\rremote: Counting objects:  90% (38/42)\u001b[K\rremote: Counting objects:  92% (39/42)\u001b[K\rremote: Counting objects:  95% (40/42)\u001b[K\rremote: Counting objects:  97% (41/42)\u001b[K\rremote: Counting objects: 100% (42/42)\u001b[K\rremote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects:   3% (1/29)\u001b[K\rremote: Compressing objects:   6% (2/29)\u001b[K\rremote: Compressing objects:  10% (3/29)\u001b[K\rremote: Compressing objects:  13% (4/29)\u001b[K\rremote: Compressing objects:  17% (5/29)\u001b[K\rremote: Compressing objects:  20% (6/29)\u001b[K\rremote: Compressing objects:  24% (7/29)\u001b[K\rremote: Compressing objects:  27% (8/29)\u001b[K\rremote: Compressing objects:  31% (9/29)\u001b[K\rremote: Compressing objects:  34% (10/29)\u001b[K\rremote: Compressing objects:  37% (11/29)\u001b[K\rremote: Compressing objects:  41% (12/29)\u001b[K\rremote: Compressing objects:  44% (13/29)\u001b[K\rremote: Compressing objects:  48% (14/29)\u001b[K\rremote: Compressing objects:  51% (15/29)\u001b[K\rremote: Compressing objects:  55% (16/29)\u001b[K\rremote: Compressing objects:  58% (17/29)\u001b[K\rremote: Compressing objects:  62% (18/29)\u001b[K\rremote: Compressing objects:  65% (19/29)\u001b[K\rremote: Compressing objects:  68% (20/29)\u001b[K\rremote: Compressing objects:  72% (21/29)\u001b[K\rremote: Compressing objects:  75% (22/29)\u001b[K\rremote: Compressing objects:  79% (23/29)\u001b[K\rremote: Compressing objects:  82% (24/29)\u001b[K\rremote: Compressing objects:  86% (25/29)\u001b[K\rremote: Compressing objects:  89% (26/29)\u001b[K\rremote: Compressing objects:  93% (27/29)\u001b[K\rremote: Compressing objects:  96% (28/29)\u001b[K\rremote: Compressing objects: 100% (29/29)\u001b[K\rremote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 42 (delta 24), reused 28 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects:   2% (1/42)   \rUnpacking objects:   4% (2/42)   \rUnpacking objects:   7% (3/42)   \rUnpacking objects:   9% (4/42)   \rUnpacking objects:  11% (5/42)   \rUnpacking objects:  14% (6/42)   \rUnpacking objects:  16% (7/42)   \rUnpacking objects:  19% (8/42)   \rUnpacking objects:  21% (9/42)   \rUnpacking objects:  23% (10/42)   \rUnpacking objects:  26% (11/42)   \rUnpacking objects:  28% (12/42)   \rUnpacking objects:  30% (13/42)   \rUnpacking objects:  33% (14/42)   \rUnpacking objects:  35% (15/42)   \rUnpacking objects:  38% (16/42)   \rUnpacking objects:  40% (17/42)   \rUnpacking objects:  42% (18/42)   \rUnpacking objects:  45% (19/42)   \rUnpacking objects:  47% (20/42)   \rUnpacking objects:  50% (21/42)   \rUnpacking objects:  52% (22/42)   \rUnpacking objects:  54% (23/42)   \rUnpacking objects:  57% (24/42)   \rUnpacking objects:  59% (25/42)   \rUnpacking objects:  61% (26/42)   \rUnpacking objects:  64% (27/42)   \rUnpacking objects:  66% (28/42)   \rUnpacking objects:  69% (29/42)   \rUnpacking objects:  71% (30/42)   \rUnpacking objects:  73% (31/42)   \rUnpacking objects:  76% (32/42)   \rUnpacking objects:  78% (33/42)   \rUnpacking objects:  80% (34/42)   \rUnpacking objects:  83% (35/42)   \rUnpacking objects:  85% (36/42)   \rUnpacking objects:  88% (37/42)   \rUnpacking objects:  90% (38/42)   \rUnpacking objects:  92% (39/42)   \rUnpacking objects:  95% (40/42)   \rUnpacking objects:  97% (41/42)   \rUnpacking objects: 100% (42/42)   \rUnpacking objects: 100% (42/42), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUAjLjBD_-wf",
        "outputId": "259918aa-afd7-483b-a112-699dfd2908c9"
      },
      "source": [
        "%cd '/content/Oversampling/OversamplingAlgo'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Oversampling/OversamplingAlgo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciwoAKpeAEue",
        "outputId": "803fbf17-7bc8-4ca0-8fa0-b8f09d0db71f"
      },
      "source": [
        "%tensorflow_version 1.x\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVqCloh8Ac4o"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aUk4B4DAitH",
        "outputId": "3dc47aa8-3fa7-41eb-b7db-ba4b443deb4d"
      },
      "source": [
        "!wget https://sci2s.ugr.es/keel/keel-dataset/datasets/imbalanced/all//imb_IRlowerThan9.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-25 02:11:32--  https://sci2s.ugr.es/keel/keel-dataset/datasets/imbalanced/all//imb_IRlowerThan9.zip\n",
            "Resolving sci2s.ugr.es (sci2s.ugr.es)... 150.214.190.154\n",
            "Connecting to sci2s.ugr.es (sci2s.ugr.es)|150.214.190.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2383109 (2.3M) [application/zip]\n",
            "Saving to: ‘imb_IRlowerThan9.zip’\n",
            "\n",
            "imb_IRlowerThan9.zi 100%[===================>]   2.27M  2.94MB/s    in 0.8s    \n",
            "\n",
            "2021-07-25 02:11:33 (2.94 MB/s) - ‘imb_IRlowerThan9.zip’ saved [2383109/2383109]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp-V2zalAo3q"
      },
      "source": [
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/ecoli-0_vs_1/ecoli-0_vs_1.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/ecoli-0_vs_1/ecoli-0_vs_1.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/ecoli1/ecoli1.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/ecoli1/ecoli1.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/ecoli2/ecoli2.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/ecoli2/ecoli2.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/ecoli3/ecoli3.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/ecoli3/ecoli3.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/glass0/glass0.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/glass0/glass0.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/glass1/glass1.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/glass1/glass1.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/glass6/glass6.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/glass6/glass6.zip\n",
        "\n",
        "# !unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/haberman/haberman.zip\n",
        "# !rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/haberman/haberman.zip\n",
        "\n",
        "# !unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/iris0/iris0.zip\n",
        "# !rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/iris0/iris0.zip\n",
        "\n",
        "# !unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/new-thyroid1/new-thyroid1.zip\n",
        "# !rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/new-thyroid1/new-thyroid1.zip\n",
        "\n",
        "# !unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/new-thyroid2/new-thyroid2.zip\n",
        "# !rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/new-thyroid2/new-thyroid2.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/page-blocks0/page-blocks0.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/page-blocks0/page-blocks0.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/pima/pima.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/pima/pima.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/segment0/segment0.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/segment0/segment0.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/vehicle0/vehicle0.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/vehicle0/vehicle0.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/vehicle1/vehicle1.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/vehicle1/vehicle1.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/vehicle2/vehicle2.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/vehicle2/vehicle2.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/vehicle3/vehicle3.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/vehicle3/vehicle3.zip\n",
        "\n",
        "# !unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/wisconsin/wisconsin.zip\n",
        "# !rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/wisconsin/wisconsin.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/yeast1/yeast1.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/yeast1/yeast1.zip\n",
        "\n",
        "!unzip /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/yeast3/yeast3.zip\n",
        "!rm -r /content/Oversampling/OversamplingAlgo/imb_IRlowerThan9/yeast3/yeast3.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmbCxueMBbHa"
      },
      "source": [
        "URLecoli0='/content/Oversampling/OversamplingAlgo/ecoli-0_vs_1.dat'\n",
        "URLecoli1='/content/Oversampling/OversamplingAlgo/ecoli1.dat'\n",
        "URLecoli2='/content/Oversampling/OversamplingAlgo/ecoli2.dat'\n",
        "URLecoli3='/content/Oversampling/OversamplingAlgo/ecoli3.dat'\n",
        "\n",
        "URLglass0='/content/Oversampling/OversamplingAlgo/glass0.dat'\n",
        "URLglass1='/content/Oversampling/OversamplingAlgo/glass1.dat'\n",
        "URLglass6='/content/Oversampling/OversamplingAlgo/glass6.dat'\n",
        "\n",
        "URLpima='/content/Oversampling/OversamplingAlgo/pima.dat'\n",
        "URLpageblock='/content/Oversampling/OversamplingAlgo/page-blocks0.dat'\n",
        "\n",
        "URLvehicle0='/content/Oversampling/OversamplingAlgo/vehicle0.dat'\n",
        "URLvehicle1='/content/Oversampling/OversamplingAlgo/vehicle1.dat'\n",
        "URLvehicle2='/content/Oversampling/OversamplingAlgo/vehicle2.dat'\n",
        "URLvehicle3='/content/Oversampling/OversamplingAlgo/vehicle3.dat'\n",
        "\n",
        "URLyeast1='/content/Oversampling/OversamplingAlgo/yeast1.dat'\n",
        "URLyeast3='/content/Oversampling/OversamplingAlgo/yeast3.dat'\n",
        "\n",
        "column_e = ['Mcg', 'Gvh', 'Lip', 'Chg', 'Aac', 'Alm1', 'Alm2', 'Class']\n",
        "column_p=[\"Preg\", \"Plas\", \"Pres\", \"Skin\", \"Insu\", \"Mass\", \"Pedi\", \"Age\",\"Class\"]\n",
        "column_g=[\"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\",\"Class\"]\n",
        "column_pb=[\"Height\", \"Lenght\", \"Area\", \"Eccen\", \"P_black\", \"P_and\", \"Mean_tr\", \"Blackpix\", \"Blackand\", \"Wb_trans\",\"Class\"]\n",
        "column_v=['Compactness', 'Circularity', 'Distance_circularity', 'Radius_ratio', 'Praxis_aspect_ratio', 'Max_length_aspect_ratio', 'Scatter_ratio', 'Elongatedness', 'Praxis_rectangular', 'Length_rectangular', 'Major_variance', 'Minor_variance', 'Gyration_radius', 'Major_skewness', 'Minor_skewness', 'Minor_kurtosis', 'Major_kurtosis', 'Hollows_ratio','Class']\n",
        "column_y=['Mcg', 'Gvh', 'Alm', 'Mit', 'Erl', 'Pox', 'Vac', 'Nuc','Class']\n",
        "# column_s=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19','Class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A18swdg4B1nw"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTQCmBqUBd6m"
      },
      "source": [
        "from DataLoad import data_preprocessing\n",
        "from GAN import GAN\n",
        "from ModelTrain import ModelTrain\n",
        "from VAE import VAE\n",
        "from DAE import DAE\n",
        "from SMOTE import SMOTE\n",
        "from ReverseSMOTE import ReverseSMOTE as rs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVCIo9Ln-f-E"
      },
      "source": [
        "# **GAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLfCbNQg6gtR"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def GAN_train(URL,k,header_name,n, sample_size):\n",
        "  d_train, d_test= data_preprocessing(URL,k,header_name)\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  d_min=d_train.loc[d_train['Class']==1]\n",
        "  print(\"Before sampling:\")\n",
        "  print(\"Minority:\",d_train.loc[d_train['Class']==1].shape[0])\n",
        "  print(\"Majority:\",d_train.loc[d_train['Class']==0].shape[0])\n",
        "  ori_data=d_min\n",
        "  # print(d_min)  #56\n",
        "  d_min=np.array(d_min)\n",
        "  X_min = d_min[:,0:-1]\n",
        "  y_min = d_min[:,-1]\n",
        "  X_min = X_min.reshape(1,X_min.shape[0],X_min.shape[1])\n",
        "\n",
        "  gan = GAN(num_epochs=100,\n",
        "              batch_size=100,\n",
        "              d_hidden_dim=(512, 256),\n",
        "              g_hidden_dim=(512, 256, 64),\n",
        "              n_input=7,  \n",
        "              stddev=0.01,  # standard deviation for initialization noise\n",
        "              pretrain=False)\n",
        "\n",
        "  gan.fit(X_min, display_step=1)\n",
        "  X_syn = gan.sample(sample_size)\n",
        "  # X_syn= min_max_scaler.transform(X_syn)\n",
        "  gan.close()\n",
        "\n",
        "  d_syn=pd.DataFrame(X_syn)\n",
        "  d_syn['Class']=1\n",
        "  generated_data=d_syn\n",
        "  df=pd.concat([d_train,d_syn])\n",
        "  df = df.sample(frac = 1)\n",
        "  print(\"After Sampling:\")\n",
        "  print(\"Minority\",df.loc[df['Class']==1].shape[0])\n",
        "  print(\"Majority\",df.loc[df['Class']==0].shape[0])\n",
        "\n",
        "  # newfileUrl = URLecoli[URLecoli.rindex('/')+1:URLecoli.rindex('.')]+\"GAN\"+\".csv\"\n",
        "  # d_syn.to_csv(newfileUrl,index=False)\n",
        "  result=ModelTrain(df,d_test)\n",
        "  result.to_csv(\"GAN_\"+n+\".csv\")\n",
        "  return ori_data, generated_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq6kmRBFN12X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07189963-5f14-4f66-e11a-b9d1705ffbe4"
      },
      "source": [
        "GAN_train(URLecoli1,12,column_e,\"Ecoli1\",100)\n",
        "GAN_train(URLecoli2,12,column_e,\"Ecoli2\",150)\n",
        "GAN_train(URLecoli3,12,column_e,\"Ecoli3\",180)\n",
        "GAN_train(URLpima,13,column_p,\"Pima\", 150)\n",
        "GAN_train(URLpageblock,15,column_pb,\"Pageblock\",2900)\n",
        "GAN_train(URLglass0,14,column_g,\"Glass0\", 47)\n",
        "GAN_train(URLglass1,14,column_g,\"Glass1\", 40)\n",
        "GAN_train(URLglass6,14,column_g,\"Glass6\",105)\n",
        "GAN_train(URLvehicle0,23,column_v,\"Vehicle0\", 310)\n",
        "GAN_train(URLvehicle1,23,column_v,\"Vehicle1\", 290)\n",
        "GAN_train(URLvehicle2,23,column_v,\"Vehicle2\", 290)\n",
        "GAN_train(URLvehicle3,23,column_v,\"Vehicle3\", 250)\n",
        "GAN_train(URLyeast1,13,column_y,\"Yeast1\",410)\n",
        "GAN_train(URLyeast1,13,column_y,\"Yeast3\",410)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of minority Class: 77\n",
            "No of majority Class: 259\n",
            "Before sampling:\n",
            "Minority: 56\n",
            "Majority: 169\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/GAN.py:215: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/GAN.py:316: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/GAN.py:317: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/GAN.py:83: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/GAN.py:353: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/GAN.py:361: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/GAN.py:229: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/GAN.py:232: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/GAN.py:234: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/GAN.py:234: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "After Sampling:\n",
            "Minority 156\n",
            "Majority 169\n",
            "No of minority Class: 52\n",
            "No of majority Class: 284\n",
            "Before sampling:\n",
            "Minority: 35\n",
            "Majority: 190\n",
            "After Sampling:\n",
            "Minority 185\n",
            "Majority 190\n",
            "No of minority Class: 35\n",
            "No of majority Class: 301\n",
            "Before sampling:\n",
            "Minority: 20\n",
            "Majority: 205\n",
            "After Sampling:\n",
            "Minority 200\n",
            "Majority 205\n",
            "No of minority Class: 268\n",
            "No of majority Class: 500\n",
            "Before sampling:\n",
            "Minority: 182\n",
            "Majority: 332\n",
            "After Sampling:\n",
            "Minority 332\n",
            "Majority 332\n",
            "No of minority Class: 559\n",
            "No of majority Class: 4913\n",
            "Before sampling:\n",
            "Minority: 370\n",
            "Majority: 3296\n",
            "After Sampling:\n",
            "Minority 3270\n",
            "Majority 3296\n",
            "No of minority Class: 70\n",
            "No of majority Class: 144\n",
            "Before sampling:\n",
            "Minority: 48\n",
            "Majority: 95\n",
            "After Sampling:\n",
            "Minority 95\n",
            "Majority 95\n",
            "No of minority Class: 76\n",
            "No of majority Class: 138\n",
            "Before sampling:\n",
            "Minority: 51\n",
            "Majority: 92\n",
            "After Sampling:\n",
            "Minority 91\n",
            "Majority 92\n",
            "No of minority Class: 29\n",
            "No of majority Class: 185\n",
            "Before sampling:\n",
            "Minority: 19\n",
            "Majority: 124\n",
            "After Sampling:\n",
            "Minority 124\n",
            "Majority 124\n",
            "No of minority Class: 199\n",
            "No of majority Class: 647\n",
            "Before sampling:\n",
            "Minority: 127\n",
            "Majority: 439\n",
            "After Sampling:\n",
            "Minority 437\n",
            "Majority 439\n",
            "No of minority Class: 217\n",
            "No of majority Class: 629\n",
            "Before sampling:\n",
            "Minority: 138\n",
            "Majority: 428\n",
            "After Sampling:\n",
            "Minority 428\n",
            "Majority 428\n",
            "No of minority Class: 218\n",
            "No of majority Class: 628\n",
            "Before sampling:\n",
            "Minority: 136\n",
            "Majority: 430\n",
            "After Sampling:\n",
            "Minority 426\n",
            "Majority 430\n",
            "No of minority Class: 212\n",
            "No of majority Class: 634\n",
            "Before sampling:\n",
            "Minority: 156\n",
            "Majority: 410\n",
            "After Sampling:\n",
            "Minority 406\n",
            "Majority 410\n",
            "No of minority Class: 429\n",
            "No of majority Class: 1055\n",
            "Before sampling:\n",
            "Minority: 288\n",
            "Majority: 706\n",
            "After Sampling:\n",
            "Minority 698\n",
            "Majority 706\n",
            "No of minority Class: 429\n",
            "No of majority Class: 1055\n",
            "Before sampling:\n",
            "Minority: 288\n",
            "Majority: 706\n",
            "After Sampling:\n",
            "Minority 698\n",
            "Majority 706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(            0         1         2     3    4    5         6     7  Class\n",
              " 3    0.511628  0.383721  0.405063  0.20  0.0  0.0  0.547945  0.22      1\n",
              " 7    0.313953  0.267442  0.443038  0.21  0.0  0.0  0.671233  0.22      1\n",
              " 12   0.337209  0.709302  0.291139  0.12  0.0  0.0  0.671233  0.22      1\n",
              " 14   0.290698  0.406977  0.430380  0.21  0.0  0.0  0.753425  0.33      1\n",
              " 22   0.546512  0.430233  0.443038  0.16  0.0  0.0  0.465753  0.22      1\n",
              " ..        ...       ...       ...   ...  ...  ...       ...   ...    ...\n",
              " 973  0.500000  0.453488  0.341772  0.14  0.0  0.0  0.671233  0.33      1\n",
              " 975  0.569767  0.534884  0.354430  0.30  0.0  0.0  0.726027  0.22      1\n",
              " 985  0.395349  0.279070  0.481013  0.18  0.0  0.0  0.602740  0.45      1\n",
              " 988  0.395349  0.313953  0.405063  0.49  0.0  0.0  0.671233  0.31      1\n",
              " 993  0.511628  0.302326  0.518987  0.22  0.0  0.0  0.506849  0.28      1\n",
              " \n",
              " [288 rows x 9 columns],\n",
              "             0         1         2  ...         5         6  Class\n",
              " 0    0.007465  0.003979 -0.001819  ...  0.003464  0.005161      1\n",
              " 1    0.001576  0.010807 -0.000186  ... -0.000721  0.005237      1\n",
              " 2    0.013535  0.004028 -0.001069  ... -0.003017  0.021407      1\n",
              " 3    0.001318  0.003301 -0.000633  ...  0.001370 -0.000095      1\n",
              " 4    0.005581  0.003301 -0.000400  ...  0.008754  0.006290      1\n",
              " ..        ...       ...       ...  ...       ...       ...    ...\n",
              " 405  0.000000  0.000000  0.000000  ...  0.000000  0.000000      1\n",
              " 406  0.000000  0.000000  0.000000  ...  0.000000  0.000000      1\n",
              " 407  0.000000  0.000000  0.000000  ...  0.000000  0.000000      1\n",
              " 408  0.000000  0.000000  0.000000  ...  0.000000  0.000000      1\n",
              " 409  0.000000  0.000000  0.000000  ...  0.000000  0.000000      1\n",
              " \n",
              " [410 rows x 8 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dP4nKViP3uz"
      },
      "source": [
        "# **VAE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E66we5PGpKy"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def VAE_train(URL,k,header_name,n,sample_size):\n",
        "  d_train, d_test= data_preprocessing(URL,k,header_name)\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  d_min=d_train.loc[d_train['Class']==1]\n",
        "  print(\"Minority:\",d_train.loc[d_train['Class']==1].shape[0])\n",
        "  print(\"Majority:\",d_train.loc[d_train['Class']==0].shape[0])\n",
        "  ori_data=d_min\n",
        "  # print(d_min)  #56\n",
        "  d_min=np.array(d_min)\n",
        "  X_min = d_min[:,0:-1]\n",
        "  y_min = d_min[:,-1]\n",
        "  X_min = X_min.reshape(1,X_min.shape[0],X_min.shape[1])\n",
        "  d_test=np.array(d_test)\n",
        "  X_test = d_test[:,0:-1]\n",
        "  y_test = d_test[:,-1] \n",
        "  vae = VAE(num_epochs=10,\n",
        "              batch_size=100,\n",
        "              hidden_dim=(512, 256),\n",
        "              n_input=ori_data.shape[1]-1,  \n",
        "              n_z=64)  # dimensionality of latent space\n",
        "  vae.fit(X_min, display_step=1)\n",
        "  # X_test_samples = X_test[:200]\n",
        "  # X_syn = vae.reconstruct(X_test_samples)\n",
        "  X_syn=vae.sample(sample_size)\n",
        "  vae.close()\n",
        "  d_syn=pd.DataFrame(X_syn)\n",
        "  d_syn['Class']=1\n",
        "  generated_data=d_syn\n",
        "\n",
        "  df=pd.concat([d_train,d_syn])\n",
        "  df = df.sample(frac = 1)\n",
        "  print(\"After Sampling:\")\n",
        "  print(\"Minority\",df.loc[df['Class']==1].shape[0])\n",
        "  print(\"Majority\",df.loc[df['Class']==0].shape[0])\n",
        "\n",
        "  result=ModelTrain(df,d_test)\n",
        "  result.to_csv(\"VAE_\"+n+\".csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCK7hNp3QUgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd94440-4566-41f6-bace-d11dce072ea0"
      },
      "source": [
        "VAE_train(URLecoli1,12,column_e,\"Ecoli1\",100)\n",
        "VAE_train(URLecoli2,12,column_e,\"Ecoli2\",150)\n",
        "VAE_train(URLecoli3,12,column_e,\"Ecoli3\",180)\n",
        "VAE_train(URLpima,13,column_p,\"Pima\", 150)\n",
        "VAE_train(URLpageblock,15,column_pb,\"Pageblock\",2900)\n",
        "VAE_train(URLglass0,14,column_g,\"Glass0\", 47)\n",
        "VAE_train(URLglass1,14,column_g,\"Glass1\", 40)\n",
        "VAE_train(URLglass6,14,column_g,\"Glass6\",105)\n",
        "VAE_train(URLvehicle0,23,column_v,\"Vehicle0\", 310)\n",
        "VAE_train(URLvehicle1,23,column_v,\"Vehicle1\", 290)\n",
        "VAE_train(URLvehicle2,23,column_v,\"Vehicle2\", 290)\n",
        "VAE_train(URLvehicle3,23,column_v,\"Vehicle3\", 250)\n",
        "VAE_train(URLyeast1,13,column_y,\"Yeast1\",410)\n",
        "VAE_train(URLyeast1,13,column_y,\"Yeast3\",410)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of minority Class: 77\n",
            "No of majority Class: 259\n",
            "Minority: 56\n",
            "Majority: 169\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/VAE.py:39: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/VAE.py:157: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/Oversampling/OversamplingAlgo/VAE.py:50: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "After Sampling:\n",
            "Minority 156\n",
            "Majority 169\n",
            "No of minority Class: 52\n",
            "No of majority Class: 284\n",
            "Minority: 35\n",
            "Majority: 190\n",
            "After Sampling:\n",
            "Minority 185\n",
            "Majority 190\n",
            "No of minority Class: 35\n",
            "No of majority Class: 301\n",
            "Minority: 20\n",
            "Majority: 205\n",
            "After Sampling:\n",
            "Minority 200\n",
            "Majority 205\n",
            "No of minority Class: 268\n",
            "No of majority Class: 500\n",
            "Minority: 182\n",
            "Majority: 332\n",
            "After Sampling:\n",
            "Minority 332\n",
            "Majority 332\n",
            "No of minority Class: 559\n",
            "No of majority Class: 4913\n",
            "Minority: 370\n",
            "Majority: 3296\n",
            "After Sampling:\n",
            "Minority 3270\n",
            "Majority 3296\n",
            "No of minority Class: 70\n",
            "No of majority Class: 144\n",
            "Minority: 48\n",
            "Majority: 95\n",
            "After Sampling:\n",
            "Minority 95\n",
            "Majority 95\n",
            "No of minority Class: 76\n",
            "No of majority Class: 138\n",
            "Minority: 51\n",
            "Majority: 92\n",
            "After Sampling:\n",
            "Minority 91\n",
            "Majority 92\n",
            "No of minority Class: 29\n",
            "No of majority Class: 185\n",
            "Minority: 19\n",
            "Majority: 124\n",
            "After Sampling:\n",
            "Minority 124\n",
            "Majority 124\n",
            "No of minority Class: 199\n",
            "No of majority Class: 647\n",
            "Minority: 127\n",
            "Majority: 439\n",
            "After Sampling:\n",
            "Minority 437\n",
            "Majority 439\n",
            "No of minority Class: 217\n",
            "No of majority Class: 629\n",
            "Minority: 138\n",
            "Majority: 428\n",
            "After Sampling:\n",
            "Minority 428\n",
            "Majority 428\n",
            "No of minority Class: 218\n",
            "No of majority Class: 628\n",
            "Minority: 136\n",
            "Majority: 430\n",
            "After Sampling:\n",
            "Minority 426\n",
            "Majority 430\n",
            "No of minority Class: 212\n",
            "No of majority Class: 634\n",
            "Minority: 156\n",
            "Majority: 410\n",
            "After Sampling:\n",
            "Minority 406\n",
            "Majority 410\n",
            "No of minority Class: 429\n",
            "No of majority Class: 1055\n",
            "Minority: 288\n",
            "Majority: 706\n",
            "After Sampling:\n",
            "Minority 698\n",
            "Majority 706\n",
            "No of minority Class: 429\n",
            "No of majority Class: 1055\n",
            "Minority: 288\n",
            "Majority: 706\n",
            "After Sampling:\n",
            "Minority 698\n",
            "Majority 706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnicahD4Vzs5"
      },
      "source": [
        "# **SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp1lriS5Uc0h"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "def SMOTE_train(URL,k,header_name,n, sample_size):\n",
        "  d_train, d_test= data_preprocessing(URL,k,header_name)\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  d_min=d_train.loc[d_train['Class']==1]\n",
        "  print(\"before sampling\")\n",
        "  print(\"Minority:\",d_train.loc[d_train['Class']==1].shape[0])\n",
        "  print(\"Majority:\",d_train.loc[d_train['Class']==0].shape[0])\n",
        "  ori_data=d_min\n",
        "  # print(d_min)  #56\n",
        "  d_min=np.array(d_min)\n",
        "  X_min = d_min[:,0:-1]\n",
        "  y_min = d_min[:,-1]\n",
        "\n",
        "  model = SMOTE(5,None)\n",
        "\n",
        "  model.fit(X_min)\n",
        "  X_syn = model.sample(sample_size)\n",
        "\n",
        "  d_syn=pd.DataFrame(X_syn)\n",
        "  d_syn['Class']=1\n",
        "  generated_data=d_syn\n",
        "\n",
        "  df=pd.concat([d_train,d_syn])\n",
        "  df = df.sample(frac = 1)\n",
        "  print(\"After Sampling:\")\n",
        "  print(\"Minority\",df.loc[df['Class']==1].shape[0])\n",
        "  print(\"Majority\",df.loc[df['Class']==0].shape[0])\n",
        "\n",
        "  # newfileUrl = URLecoli[URLecoli.rindex('/')+1:URLecoli.rindex('.')]+\"GAN\"+\".csv\"\n",
        "  # d_syn.to_csv(newfileUrl,index=False)\n",
        "  result=ModelTrain(df,d_test)\n",
        "  result.to_csv(\"SMOTE_\"+n+\".csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Qez80SV3Kp"
      },
      "source": [
        "SMOTE_train(URLecoli1,12,column_e,\"Ecoli1\",100)\n",
        "SMOTE_train(URLecoli2,12,column_e,\"Ecoli2\",150)\n",
        "SMOTE_train(URLecoli3,12,column_e,\"Ecoli3\",180)\n",
        "SMOTE_train(URLpima,13,column_p,\"Pima\", 150)\n",
        "SMOTE_train(URLpageblock,15,column_pb,\"Pageblock\",2900)\n",
        "SMOTE_train(URLglass0,14,column_g,\"Glass0\", 47)\n",
        "SMOTE_train(URLglass1,14,column_g,\"Glass1\", 40)\n",
        "SMOTE_train(URLglass6,14,column_g,\"Glass6\",105)\n",
        "SMOTE_train(URLvehicle0,23,column_v,\"Vehicle0\", 310)\n",
        "SMOTE_train(URLvehicle1,23,column_v,\"Vehicle1\", 290)\n",
        "SMOTE_train(URLvehicle2,23,column_v,\"Vehicle2\", 290)\n",
        "SMOTE_train(URLvehicle3,23,column_v,\"Vehicle3\", 250)\n",
        "SMOTE_train(URLyeast1,13,column_y,\"Yeast1\",410)\n",
        "SMOTE_train(URLyeast1,13,column_y,\"Yeast3\",410)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksIyTG8oWB6s"
      },
      "source": [
        "# **Reerse SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO6ZwfcXLW77"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "def RSMOTE_train(URL,k,header_name,n,sample_size):\n",
        "  d_train, d_test= data_preprocessing(URL,k,header_name)\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  d_min=d_train.loc[d_train['Class']==1]\n",
        "  print('Before Sampling:')\n",
        "  print(\"Minority:\",d_train.loc[d_train['Class']==1].shape[0])\n",
        "  print(\"Majority:\",d_train.loc[d_train['Class']==0].shape[0])\n",
        "  ori_data=d_min\n",
        "  # print(ori_data)  #56\n",
        "  d_min=np.array(d_min)\n",
        "  X_min = d_min[:,0:-1]\n",
        "  y_min = d_min[:,-1]\n",
        "  model = rs(5,None)\n",
        "  model.fit(X_min)\n",
        "  X_syn = model.sample(sample_size)\n",
        "\n",
        "  d_syn=pd.DataFrame(X_syn)\n",
        "  d_syn['Class']=1\n",
        "  generated_data=d_syn\n",
        "\n",
        "  df=pd.concat([d_train,d_syn])\n",
        "  df = df.sample(frac = 1)\n",
        "  print(\"After Sampling:\")\n",
        "  print(\"Minority\",df.loc[df['Class']==1].shape[0])\n",
        "  print(\"Majority\",df.loc[df['Class']==0].shape[0])\n",
        "\n",
        "  # newfileUrl = URLecoli[URLecoli.rindex('/')+1:URLecoli.rindex('.')]+\"GAN\"+\".csv\"\n",
        "  # d_syn.to_csv(newfileUrl,index=False)\n",
        "  result=ModelTrain(df,d_test)\n",
        "  result.to_csv(\"RSMOTE_\"+n+\".csv\")\n",
        "  return ori_data, generated_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtBW59WuW3B5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9652d856-5f37-454d-e3de-6d5048c76e74"
      },
      "source": [
        "RSMOTE_train(URLecoli1,12,column_e,\"Ecoli1\",100)\n",
        "RSMOTE_train(URLecoli2,12,column_e,\"Ecoli2\",150)\n",
        "RSMOTE_train(URLecoli3,12,column_e,\"Ecoli3\",180)\n",
        "RSMOTE_train(URLpima,13,column_p,\"Pima\", 150)\n",
        "RSMOTE_train(URLpageblock,15,column_pb,\"Pageblock\",2900)\n",
        "RSMOTE_train(URLglass0,14,column_g,\"Glass0\", 47)\n",
        "RSMOTE_train(URLglass1,14,column_g,\"Glass1\", 40)\n",
        "RSMOTE_train(URLglass6,14,column_g,\"Glass6\",105)\n",
        "RSMOTE_train(URLvehicle0,23,column_v,\"Vehicle0\", 310)\n",
        "RSMOTE_train(URLvehicle1,23,column_v,\"Vehicle1\", 290)\n",
        "RSMOTE_train(URLvehicle2,23,column_v,\"Vehicle2\", 290)\n",
        "RSMOTE_train(URLvehicle3,23,column_v,\"Vehicle3\", 250)\n",
        "RSMOTE_train(URLyeast1,13,column_y,\"Yeast1\",410)\n",
        "RSMOTE_train(URLyeast1,13,column_y,\"Yeast3\",410)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of minority Class: 77\n",
            "No of majority Class: 259\n",
            "Before Sampling:\n",
            "Minority: 56\n",
            "Majority: 169\n",
            "After Sampling:\n",
            "Minority 156\n",
            "Majority 169\n",
            "No of minority Class: 52\n",
            "No of majority Class: 284\n",
            "Before Sampling:\n",
            "Minority: 35\n",
            "Majority: 190\n",
            "After Sampling:\n",
            "Minority 185\n",
            "Majority 190\n",
            "No of minority Class: 35\n",
            "No of majority Class: 301\n",
            "Before Sampling:\n",
            "Minority: 20\n",
            "Majority: 205\n",
            "After Sampling:\n",
            "Minority 200\n",
            "Majority 205\n",
            "No of minority Class: 268\n",
            "No of majority Class: 500\n",
            "Before Sampling:\n",
            "Minority: 182\n",
            "Majority: 332\n",
            "After Sampling:\n",
            "Minority 332\n",
            "Majority 332\n",
            "No of minority Class: 559\n",
            "No of majority Class: 4913\n",
            "Before Sampling:\n",
            "Minority: 370\n",
            "Majority: 3296\n",
            "After Sampling:\n",
            "Minority 3270\n",
            "Majority 3296\n",
            "No of minority Class: 70\n",
            "No of majority Class: 144\n",
            "Before Sampling:\n",
            "Minority: 48\n",
            "Majority: 95\n",
            "After Sampling:\n",
            "Minority 95\n",
            "Majority 95\n",
            "No of minority Class: 76\n",
            "No of majority Class: 138\n",
            "Before Sampling:\n",
            "Minority: 51\n",
            "Majority: 92\n",
            "After Sampling:\n",
            "Minority 91\n",
            "Majority 92\n",
            "No of minority Class: 29\n",
            "No of majority Class: 185\n",
            "Before Sampling:\n",
            "Minority: 19\n",
            "Majority: 124\n",
            "After Sampling:\n",
            "Minority 124\n",
            "Majority 124\n",
            "No of minority Class: 199\n",
            "No of majority Class: 647\n",
            "Before Sampling:\n",
            "Minority: 127\n",
            "Majority: 439\n",
            "After Sampling:\n",
            "Minority 437\n",
            "Majority 439\n",
            "No of minority Class: 217\n",
            "No of majority Class: 629\n",
            "Before Sampling:\n",
            "Minority: 138\n",
            "Majority: 428\n",
            "After Sampling:\n",
            "Minority 428\n",
            "Majority 428\n",
            "No of minority Class: 218\n",
            "No of majority Class: 628\n",
            "Before Sampling:\n",
            "Minority: 136\n",
            "Majority: 430\n",
            "After Sampling:\n",
            "Minority 426\n",
            "Majority 430\n",
            "No of minority Class: 212\n",
            "No of majority Class: 634\n",
            "Before Sampling:\n",
            "Minority: 156\n",
            "Majority: 410\n",
            "After Sampling:\n",
            "Minority 406\n",
            "Majority 410\n",
            "No of minority Class: 429\n",
            "No of majority Class: 1055\n",
            "Before Sampling:\n",
            "Minority: 288\n",
            "Majority: 706\n",
            "After Sampling:\n",
            "Minority 698\n",
            "Majority 706\n",
            "No of minority Class: 429\n",
            "No of majority Class: 1055\n",
            "Before Sampling:\n",
            "Minority: 288\n",
            "Majority: 706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjVKJ64fM9jD"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/jsyoon0823/TimeGAN/master/metrics/visualization_metrics.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBcCkVtT4PNm"
      },
      "source": [
        "# Necessary packages\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# from visualization_metrics import visualization\n",
        "   \n",
        "def visualization (ori_data, generated_data, analysis):\n",
        "  # Analysis sample size (for faster computation)\n",
        "  anal_sample_no = min([1000, len(ori_data)])\n",
        "  idx = np.random.permutation(len(ori_data))[:anal_sample_no]\n",
        "  # print(ori_data)\n",
        "  # Data preprocessing\n",
        "  ori_data = np.asarray(ori_data)\n",
        "  generated_data = np.asarray(generated_data)  \n",
        "\n",
        "  ori_data = ori_data[idx]\n",
        "  generated_data = generated_data[idx]\n",
        "  print(ori_data.shape)\n",
        "  no, dim = ori_data.shape  \n",
        "        \n",
        "  colors = [\"red\" for i in range(anal_sample_no)] + [\"blue\" for i in range(anal_sample_no)]    \n",
        "\n",
        "  if analysis == 'pca':\n",
        "    # PCA Analysis\n",
        "    pca = PCA(n_components = 2)\n",
        "    pca.fit(ori_data)\n",
        "    pca_results = pca.transform(ori_data)\n",
        "    pca_hat_results = pca.fit_transform(generated_data)\n",
        "    # visualization(ori_data, generated_data, 'pca')\n",
        "    # Plotting\n",
        "    f, ax = plt.subplots(1)    \n",
        "    plt.scatter(pca_results[:,0], pca_results[:,1],\n",
        "                c = colors[:anal_sample_no], alpha = 0.2, label = \"Original\")\n",
        "    plt.scatter(pca_hat_results[:,0], pca_hat_results[:,1], \n",
        "                c = colors[anal_sample_no:], alpha = 0.2, label = \"Synthetic\")\n",
        "\n",
        "    ax.legend()  \n",
        "    plt.title('PCA plot')\n",
        "    plt.xlabel('x-pca')\n",
        "    plt.ylabel('y_pca')\n",
        "    plt.show()\n",
        "    \n",
        "  elif analysis == 'tsne':\n",
        "    \n",
        "    # Do t-SNE Analysis together       \n",
        "    prep_data_final = np.concatenate((ori_data, generated_data), axis = 0)\n",
        "\n",
        "    # TSNE anlaysis\n",
        "    tsne = TSNE(n_components = 2, verbose = 1, perplexity = 40, n_iter = 300)\n",
        "    tsne_results = tsne.fit_transform(ori_data)\n",
        "    tsne_results1=tsne.fit_transform(generated_data)\n",
        "    # colors = [\"red\" for i in range(anal_sample_no)] + [\"blue\" for i in range(anal_sample_no)] \n",
        "    # Plotting\n",
        "    f, ax = plt.subplots(1)\n",
        "      \n",
        "    plt.scatter(tsne_results[:,0], tsne_results[:,1],\n",
        "                c = colors[:anal_sample_no], alpha = 0.2, label = \"Original\")\n",
        "    plt.scatter(tsne_results1[:,0], tsne_results1[:,1], \n",
        "                c = colors[anal_sample_no:], alpha = 0.2, label = \"Synthetic\")\n",
        "\n",
        "    ax.legend()\n",
        "      \n",
        "    plt.title('t-SNE plot')\n",
        "    plt.xlabel('x-tsne')\n",
        "    plt.ylabel('y_tsne')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBupn2N-4kux"
      },
      "source": [
        "visualization(ori_data, generated_data,'pca')\n",
        "visualization(ori_data, generated_data,'tsne')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L18GY9o2cv9"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "# calculate the fpr and tpr for all thresholds of the classification\n",
        "probs = model.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "# method I: plt\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()\n",
        "\n",
        "# method II: ggplot\n",
        "from ggplot import *\n",
        "df = pd.DataFrame(dict(fpr = fpr, tpr = tpr))\n",
        "ggplot(df, aes(x = 'fpr', y = 'tpr')) + geom_line() + geom_abline(linetype = 'dashed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbt0g2WiW9Q9"
      },
      "source": [
        "# **DAE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZpfNa8vMULH"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=Warning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def DAE_train(URL,k,header_name,n):\n",
        "  d_train, d_test= data_preprocessing(URL,k,header_name)\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  d_min=d_train.loc[d_train['Class']==1]\n",
        "  print(\"Minority:\",d_train.loc[d_train['Class']==1].shape[0])\n",
        "  print(\"Majority:\",d_train.loc[d_train['Class']==0].shape[0])\n",
        "  ori_data=d_min\n",
        "  # print(d_min)  #56\n",
        "  d_min=np.array(d_min)\n",
        "  X_min = d_min[:,0:-1]\n",
        "  y_min = d_min[:,-1]\n",
        "  X_min = X_min.reshape(1,X_min.shape[0],X_min.shape[1])\n",
        "  d_test=np.array(d_test)\n",
        "  X_test = d_test[:,0:-1]\n",
        "  y_test = d_test[:,-1]\n",
        "  dae = DAE(num_epochs=10,\n",
        "            batch_size=100,\n",
        "            hidden_dim=(512, 256, 64),\n",
        "            n_input=ori_data.shape[1]-1,  \n",
        "            corrupt_type='salt_and_pepper',\n",
        "            corrupt_prob=0.3,\n",
        "            walkbacks=0)\n",
        "\n",
        "  dae.fit(X_min, display_step=1)\n",
        "  X_test_samples = X_test[:100]\n",
        "  X_syn = dae.reconstruct(X_test_samples)\n",
        "\n",
        "  d_syn=pd.DataFrame(X_syn)\n",
        "  d_syn['Class']=1\n",
        "  generated_data=d_syn\n",
        "\n",
        "  df=pd.concat([d_train,d_syn])\n",
        "  df = df.sample(frac = 1)\n",
        "  print(\"After Sampling:\")\n",
        "  print(\"Minority\",df.loc[df['Class']==1].shape[0])\n",
        "  print(\"Majority\",df.loc[df['Class']==0].shape[0])\n",
        "\n",
        "  # newfileUrl = URLecoli[URLecoli.rindex('/')+1:URLecoli.rindex('.')]+\"GAN\"+\".csv\"\n",
        "  # d_syn.to_csv(newfileUrl,index=False)\n",
        "  result=ModelTrain(df,d_test)\n",
        "  result.to_csv(\"DAE_\"+n+\".csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx5NbeY9XVsS"
      },
      "source": [
        "DAE_train(URLecoli,12,column_e,\"Ecoli\")\n",
        "DAE_train(URLpima,13,column_p,\"Pima\")\n",
        "DAE_train(URLpageblock,15,column_pb,\"Pageblock\")\n",
        "DAE_train(URLsegment,24,column_s,\"Segment\")\n",
        "DAE_train(URLglass,14,column_g,\"Glass\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDtU-ufq4SPe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}